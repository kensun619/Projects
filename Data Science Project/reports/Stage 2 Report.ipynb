{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CS 838 &mdash; Data Science: Principles, Algorithms, and Applications; Spring 2017 ###\n",
    "\n",
    "#  Stage 2: extracting structured information from raw data #\n",
    "\n",
    "#### Trang Ho, Thomas Ngo, Qinyuan Sun\n",
    "\n",
    "*****\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1. [Introduction](#1.Introduction)\n",
    "1. [Dataset](#2.Dataset)\n",
    "1. [Training](#3.Training)\n",
    "1. [Links](#4.Links)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Introduction ##\n",
    "In this project stage, our team performed information extraction (IE) from natural text documents by using a supervised learning approach. In particular, we extracted names of tertiary educational affiliations from 300 [The New York Times](https://www.nytimes.com/) articles. \n",
    "\n",
    "We manually marked up the educational affliliation names with < pos >...</ pos > to indicate positive examples for the supervised learning. Some of the positive examples including \"University of California, Berkeley\", \"University of Arizona\", \"Harvard Business School\" and \"California State University-Los Angeles\".\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Dataset ##\n",
    "\n",
    "We set aside 100 text documents as [test set](https://github.com/TrangHo/cs838-code/tree/master/test-examples) to generate testing examples and use the rest of text documents as [train set](https://github.com/TrangHo/cs838-code/tree/master/train-texts) to generate training examples.\n",
    "\n",
    "|                | Num. of documents| Num. of positive examples  | Num. of negative examples|\n",
    "| -------------  |:----------------:| :-------------:            | :-------------:          |\n",
    "| Training Set I | 200              |     725                    |  1948                    |\n",
    "| Testing Set J  | 100              |     359                    |   898                    |\n",
    "| Total          | 300              |     1084                   |  2846                    |\n",
    "\n",
    "\n",
    "\n",
    "Subsequently, we used [four main regular-expression patterns](https://github.com/TrangHo/cs838-code/blob/master/src/lib/constants/patterns.py) to create a pool of potential negative-example candidates. The patterns suggest the following characteristics of negative candidates:\n",
    "\n",
    "- having at least 2 words and all of them are capitalized\n",
    "- having 2 captialized words with a prefix of at/from/in\n",
    "- consisting of 3 or 4 words with a suffix of a noun usually goes with univerisities such as professor/student/etc.\n",
    "- consisting of 3 or words with a prefix of a verb usually goes with with universities such as attend/receive\n",
    "\n",
    "The final negative examples were then randomly selected from the pool. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Training ##\n",
    "\n",
    "To generate feature vectors from the positive and negative examples, we eventually designed 17 functions that (1) take a string and its surrounding texts, and (2) output either zero or one. Therefore our feature vector has 17 dimensions.\n",
    "\n",
    "The machine learning algoirthms we employed are: \n",
    "- Support vector machine\n",
    "- Decision tree\n",
    "- Random forest\n",
    "- Linear regresion\n",
    "- Logistic regression \n",
    "- Multilayer perceptron neural network\n",
    "\n",
    "\n",
    "We initially had only 16 features. The average precision and recall of 5-fold cross-validation are listed as follow. However, the results of our classifiers were close but did not meet the requirement of having (1) precision of 90% or higher and (2) recall of 50% or higher. After inspecting the false positives and false negatives, we found out that a prevalent problem was that single-word university names (such as Yale, Standford, and Columbia) were wrongly classifed as negatives. As a result, we added a dictionary of short names for popular universities for these case as feature 17. This feature significantly increases both precisons and recalls of all classifiers.\n",
    "\n",
    "__Precision & Recall with 16 Features__\n",
    "\n",
    "| Machine Learning Algorithm| Ave CV Precision | Ave CV Recall  |     F1    |\n",
    "| ------------------------- |:----------------:| :-------------:|:---------:|\n",
    "| Support Vector Machine    | 0.92             |     0.49       | 0.64      |\n",
    "| Decsion Tree              | 0.89             |     0.54       | 0.67      | \n",
    "| Random Forest             | 0.89             |     0.54       | 0.67      | \n",
    "| Logistic Regression       | 0.90             |     0.50       | 0.64      | \n",
    "| Neural Network            | 0.88             |     0.54       | 0.67      | \n",
    "\n",
    "__Precision & Recall with 17 Features__\n",
    "\n",
    "| Machine Learning Algorithm| Ave CV Precision | Ave CV Recall  |     F1    |\n",
    "| ------------------------- |:----------------:| :-------------:|:---------:|\n",
    "| Support Vector Machine    | 0.95             |     0.70       | 0.81      |\n",
    "| Decsion Tree              | 0.93             |     0.72       | 0.81      |\n",
    "| Random Forest             | 0.92             |     0.74       | 0.82      |\n",
    "| Linear Regression         | 0.97             |     0.67       | 0.79      |\n",
    "| Logistic Regression       | 0.95             |     0.70       | 0.81      |\n",
    "| Neural Network            | 0.92             |     0.73       | 0.81      |\n",
    "\n",
    "We chose Support Vector Machine as our classifier. We trained the classifier with all the training examples and tested on the testing examples. The results are shown in the following table.\n",
    "\n",
    "|Type  |Precision| Recall |F1  |\n",
    "| ---- |:-------:|:------:|:--:|\n",
    "|TRAIN |0.93     | 0.73   |0.82|\n",
    "|TEST  |0.97     | 0.72   |0.83|\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Links ##\n",
    "\n",
    "[link](https://github.com/TrangHo/cs838-code/tree/master/texts) to 300 text document\n",
    "\n",
    "[link](https://github.com/TrangHo/cs838-code/tree/master/train-texts) to training set\n",
    "\n",
    "[link](https://github.com/TrangHo/cs838-code/tree/master/test-examples) to test set\n",
    "\n",
    "[link](https://github.com/TrangHo/cs838-code/tree/master/src) to source code\n",
    "\n",
    "[link](https://github.com/TrangHo/cs838-spring2017/raw/master/cs838-stage2.zip) to a zip file for stage 2 related documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
