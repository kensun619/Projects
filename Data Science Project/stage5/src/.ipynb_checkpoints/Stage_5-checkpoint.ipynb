{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project stage you will do some data analysis on the integrated and cleaned table, to infer insights. This analysis is something of your own choosing. But it must involve one of the key techniques that we will cover in the class: classification, clustering, correlation discovery, anomaly detection, or OLAP-style exploration. I will discuss more in the class. \n",
    "\n",
    "What to submit\n",
    "\n",
    "Submit the following on your group's website: \n",
    "- a CSV file storing Table E, the integrated table which is the output of project stage 4. \n",
    "- a pdf file that discusses the following issues: \n",
    "    - Statistics on Table E: specifically, what is the schema of Table E, how many tuples are in Table E? Give at least four sample tuples from Table E. \n",
    "    - What was the data analysis task that you wanted to do? (Example: we wanted to know if we can use the rest of the attributes to accurately predict the value of the attribute loan_repaid.) For that task, describe in detail the data analysis process that you went through. \n",
    "    - Give any accuracy numbers that you have obtained (such as precision and recall for your classification scheme). \n",
    "    - What did you learn/conclude from your data analysis? Were there any problems with the analysis process and with the data? \n",
    "    - If you have more time, what would you propose you can do next? \n",
    "\n",
    "\n",
    "visualize thi pyplot\n",
    "\n",
    "calculate thi Numpy, Scipy\n",
    "\n",
    "Scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy, sklearn, matplotlib\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid 35585\n",
      "pid uniq 25492\n",
      "ipeds_aid 35585\n",
      "ipeds_aid uniq 921\n",
      "year 35585\n",
      "year uniq 9\n",
      "year uniq [2006 2007 2008 2009 2010 2011 2012 2013 2014]\n"
     ]
    }
   ],
   "source": [
    "working_dir = os.path.dirname(os.getcwd())\n",
    "path_to_csv_dir = working_dir + os.sep + 'data'+ os.sep\n",
    "data = pandas.read_csv(path_to_csv_dir + '_aom_mapped_v2.csv')\n",
    "np_data = np.array(data)\n",
    "\n",
    "print('pid', len(data['pid']))\n",
    "print('pid uniq',len(np.unique(data['pid'])))\n",
    "\n",
    "print('ipeds_aid', len(data['ipeds_aid']))\n",
    "print('ipeds_aid uniq',len(np.unique(data['ipeds_aid'])))\n",
    "\n",
    "print('year', len(data['year']))\n",
    "print('year uniq',len(np.unique(data['year'])))\n",
    "print('year uniq',np.unique(data['year']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_2006 = data[data['year'] == 2006]\n",
    "data_2007 = data[data['year'] == 2007]\n",
    "data_2008 = data[data['year'] == 2008]\n",
    "data_2009 = data[data['year'] == 2009]\n",
    "data_2010 = data[data['year'] == 2010]\n",
    "data_2011 = data[data['year'] == 2011]\n",
    "data_2012 = data[data['year'] == 2012]\n",
    "data_2013 = data[data['year'] == 2013]\n",
    "data_2014 = data[data['year'] == 2014]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## School with most attendees by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-cf925865e7c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# df.groupby(\"ipeds_aid\").agg({\"pid\": np.count, \"user_id\": pd.Series.nunique})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata_2006\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ipeds_aid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"pid\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "data_2006[['ipeds_aid', 'pid']]\n",
    "\n",
    "# df.groupby(\"ipeds_aid\").agg({\"pid\": np.count, \"user_id\": pd.Series.nunique})\n",
    "data_2006.groupby(\"ipeds_aid\").agg({\"pid\": pd.Series.nunique})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Correlation between school types/sizes and number of attendees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
